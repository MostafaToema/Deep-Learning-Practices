{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab06_recap.ipynb","provenance":[{"file_id":"1Rs5UPSC09rFWMHmDeTb7TvRpPRBKzx2X","timestamp":1637400924846},{"file_id":"1wtpz9f43z_62eIhlL_YqBL0B0nNIefOk","timestamp":1633696173735},{"file_id":"1m7yKudreYZedPy8LnT0BlNxCp0hPTF01","timestamp":1633172206364}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nIsTWNrUkHlz"},"source":["# Introduction\n","In this notebook, we are using the Keras API in Tensorflow 2.X to build an image classifier to recognize Handwritten digits using the Mnist data."]},{"cell_type":"markdown","metadata":{"id":"A9jkOW0BkFoO"},"source":["# Loading Tensorflow and checking the version"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whClKcLBkVLV","executionInfo":{"status":"ok","timestamp":1637401009149,"user_tz":-120,"elapsed":1861,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}},"outputId":"f8c574c4-5659-4df2-af06-70436904fa3d"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.7.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"72OsafxTkePO"},"source":["- If not installed, uncomment the following cell. \n","- **PS:** using pip not conda as everything on colab is prepared for you (cuda)."]},{"cell_type":"code","metadata":{"id":"JL5w4z1qkfCn","executionInfo":{"status":"ok","timestamp":1637401009157,"user_tz":-120,"elapsed":118,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["#!pip install tensorflow==2.5.0 "],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xAUyfyCGkosR"},"source":["# Data Loading and exploring"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuoR7D5Oksiu","executionInfo":{"status":"ok","timestamp":1637401009913,"user_tz":-120,"elapsed":863,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}},"outputId":"5b42131c-d2b8-494b-9daa-9ade46266b7d"},"source":["from tensorflow.keras.datasets import mnist\n","\n","(training_images, training_labels),(testing_images, testing_labels) = mnist.load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_Lgse1mloXb","executionInfo":{"status":"ok","timestamp":1637401009918,"user_tz":-120,"elapsed":165,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}},"outputId":"3e632bb9-9d5c-4695-f512-9ef83d35a083"},"source":["print(\"The number of training images is {}\".format(training_images.shape[0]))\n","print(\"The number of testing images is {}\".format(testing_images.shape[0]))\n","print(\"The shape of an image is {}X{}\".format(training_images.shape[1],\n","                                              training_images.shape[2]))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of training images is 60000\n","The number of testing images is 10000\n","The shape of an image is 28X28\n"]}]},{"cell_type":"code","metadata":{"id":"wJYUk6GrlGmp","executionInfo":{"status":"ok","timestamp":1637401009923,"user_tz":-120,"elapsed":154,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["import numpy as np\n","import random\n","np.set_printoptions(linewidth=200)\n","import matplotlib.pyplot as plt"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"YboJdayulamy","executionInfo":{"status":"ok","timestamp":1637401009932,"user_tz":-120,"elapsed":160,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}},"outputId":"eb70ea14-6cda-4bcb-fec6-ec044b0d42b8"},"source":["img_number = random.randint(0, training_images.shape[0])\n","plt.imshow(training_images[img_number])\n","print(training_labels[img_number])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"FsFk7rY5mWpo"},"source":["All of the pixels values are between 0 and 255. If we are training a neural network, for various reasons it's easier that all values are between 0 and 1.\n","\n","This can be done using `normalizing`"]},{"cell_type":"code","metadata":{"id":"kb7d3LjcnB58","executionInfo":{"status":"ok","timestamp":1637401011203,"user_tz":-120,"elapsed":1385,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["training_images  = training_images / 255.0\n","testing_images = testing_images / 255.0"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EUo8UBQHp_N4"},"source":["# User Defined Callbacks\n","Callbacks are used to control the training. For example, to stop the training once the desired metric reached a certain value.\n","\n","Here, we will define a callback to stop the training once the training accuracy reaches **98%**"]},{"cell_type":"code","metadata":{"id":"nLJf_l3JqouV","executionInfo":{"status":"ok","timestamp":1637401011208,"user_tz":-120,"elapsed":36,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["from tensorflow.keras.callbacks import Callback\n","\n","class myCallback( Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>0.98):\n","      print(\"\\nReached 98% accuracy so cancelling training!\")\n","      self.model.stop_training = True"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VXQ0kOROnflN"},"source":["# Defining the model using **Sequential** API"]},{"cell_type":"code","metadata":{"id":"p9rkDIjdngXM","executionInfo":{"status":"ok","timestamp":1637401011217,"user_tz":-120,"elapsed":38,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Flatten"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"56pQNcXJnoQu","executionInfo":{"status":"ok","timestamp":1637401016021,"user_tz":-120,"elapsed":4837,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["model = Sequential([Flatten(input_shape=(28,28)), \n","                    Dense(128, activation=tf.nn.relu), \n","                    Dense(10, activation=tf.nn.softmax)])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzAMbAzMtSWw","executionInfo":{"status":"ok","timestamp":1637401016025,"user_tz":-120,"elapsed":61,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}},"outputId":"eb202bbd-b53b-4b6b-c203-3caca134e8aa"},"source":["model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 128)               100480    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 101,770\n","Trainable params: 101,770\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"nmI9EO-8n9U4"},"source":["Define the **optimizer** and the **loss**"]},{"cell_type":"code","metadata":{"id":"cVS9wyG9n_cE","executionInfo":{"status":"ok","timestamp":1637401016030,"user_tz":-120,"elapsed":49,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4m-li45MojR6"},"source":["Train the model"]},{"cell_type":"code","metadata":{"id":"94PtEBCwog6s","executionInfo":{"status":"ok","timestamp":1637401016035,"user_tz":-120,"elapsed":49,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["callbacks = myCallback() # user defined callback to stop the training once reach certain accuracy"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"goeXHiZg9GZk","executionInfo":{"status":"ok","timestamp":1637401016038,"user_tz":-120,"elapsed":47,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}}},"source":["# define a call back to save model checkpoints \n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Create a callback that saves the model's weights\n","# to save all checkpoints, uncomment the following lines\n","#checkpoint_path = \"training_1/cp-{epoch:04d}.ckpt\"\n","#cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n","#                                                 save_weights_only=True,\n","#                                                 verbose=1)\n","\n","# Save only the check point with the best acc\n","checkpoint_path = \"training_1/cp-best.ckpt\"\n","cp_callback = ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    save_weights_only=True,\n","    monitor='accuracy',\n","    mode='max',\n","    save_best_only=True)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5haywRVF9SRC","executionInfo":{"status":"ok","timestamp":1637401040127,"user_tz":-120,"elapsed":24132,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}},"outputId":"37a8d604-d452-4027-8847-be32b0831374"},"source":["model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks, cp_callback])"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1875/1875 [==============================] - 8s 3ms/step - loss: 0.2605 - accuracy: 0.9253\n","Epoch 2/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.1116 - accuracy: 0.9667\n","Epoch 3/10\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9769\n","Epoch 4/10\n","1865/1875 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9828\n","Reached 98% accuracy so cancelling training!\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0573 - accuracy: 0.9829\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5df06c0ad0>"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"7qQXQdWnolTu"},"source":["Evaluate the model on the test images"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nC_Ium0nooci","executionInfo":{"status":"ok","timestamp":1637401041225,"user_tz":-120,"elapsed":1155,"user":{"displayName":"Mostafa Saleh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsluIfaJLuZDrUwtbRFqYrV07c9I3bkbomTfEF6Q=s64","userId":"10579162633432800721"}},"outputId":"de937515-be93-4560-dc3e-bbdaac39051d"},"source":["evaluation = model.evaluate(testing_images, testing_labels)\n","print(\"Accuracy on the testing images is {}\".format(evaluation[1]*100))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.9738\n","Accuracy on the testing images is 97.3800003528595\n"]}]}]}